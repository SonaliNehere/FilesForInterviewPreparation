05-12-2025	Namura 
‚úÖ 1. Project ‚Äì Why Redis over Relational Database?

Redis is not a replacement for relational DB.
I used Redis as a cache because:

‚úî Performance
Redis stores data in memory ‚Üí ~1‚Äì2 ms latency
Database queries take 10‚Äì50 ms or more.

‚úî Offloads DB
Redis reduces database calls by 60‚Äì80%.
Higher throughput

‚úî Useful Structures
Key-value, Lists, Sets, Sorted Sets ‚Üí perfect for caching
TTL support automatically expires data.

‚úî Distributed Locks
Helps in concurrency control.

‚úî Pub/Sub
Good for notifications, streams.

Conclusion:
Relational DB = storage + transactions
Redis = caching + speed + concurrency features

‚úÖ 2. How You Secured Your Application?

I implemented multiple layers:

üîê 1. Authentication
Spring Security
JWT tokens
Password hashing using BCrypt

üîê 2. Authorization
Role-based access:
@PreAuthorize("hasRole('ADMIN')")

üîê 3. Input Validation
Bean validation
Prevent SQL injection

üîê 4. HTTPS + CORS
Enforced HTTPS
Configured CORS for frontend domain.

üîê 5. Exception Handling
Generic error messages ‚Üí no internal details exposed.

üîê 6. Rate Limiting + Throttling
Prevent brute-force attacks.

‚úÖ 3. JWT Implementation Code + How JWT Works
‚úî JWT Workflow
User logs in ‚Üí sends username/password
Server validates
Server generates JWT containing:
	username, roles, expiry time
Client stores JWT
For every request, JWT is sent in header
Server validates signature and expiry
If valid ‚Üí user authorized

‚úî Spring Boot JWT Code (Simple & Interview Ready)
üî∏ Generate Token
public String generateToken(UserDetails userDetails) {
    return Jwts.builder()
            .setSubject(userDetails.getUsername())
            .claim("roles", userDetails.getAuthorities())
            .setIssuedAt(new Date())
            .setExpiration(new Date(System.currentTimeMillis() + 1000 * 60 * 60))
            .signWith(SignatureAlgorithm.HS256, secretKey)
            .compact();
}

üî∏ Validate Token
public boolean validateToken(String token, UserDetails userDetails) {
    String username = extractUsername(token);
    return username.equals(userDetails.getUsername()) && !isExpired(token);
}

üî∏ Filter Class
String token = request.getHeader("Authorization").substring(7);
String username = jwtService.extractUsername(token);
UserDetails user = userDetailsService.loadUserByUsername(username);

if (jwtService.validateToken(token, user)) {
    UsernamePasswordAuthenticationToken auth =
            new UsernamePasswordAuthenticationToken(user, null, user.getAuthorities());
    SecurityContextHolder.getContext().setAuthentication(auth);
}

‚úÖ 4. How You Configure Security in Spring Boot?
‚úî Spring Security 6+ (No WebSecurityConfigurerAdapter)
@Bean
public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
    return http
            .csrf(csrf -> csrf.disable())
            .authorizeHttpRequests(auth -> auth
                    .requestMatchers("/auth/**").permitAll()
                    .anyRequest().authenticated())
            .sessionManagement(sm -> sm.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
            .addFilterBefore(jwtFilter, UsernamePasswordAuthenticationFilter.class)
            .build();
}

‚úÖ 5. Implement Custom LinkedList ‚Äì Why Node Should Be Inside Main Class?
‚úî Why Node class is inside LinkedList class?

Because:
Encapsulation ‚Üí Node shouldn‚Äôt be used outside LinkedList
Internal representation ‚Üí Users should not interact with Node
Keeps code organized ‚Üí Node depends only on LinkedList

‚úî Is it necessary?
‚ùå No.
Node can be outside class also.
But inner class is preferred for encapsulation.

‚úÖ 6. Improve Time Complexity of Add Operation in LinkedList
Current issue:
If you add at end without tail pointer ‚Üí O(n)

Solution:
Maintain tail pointer.

Result:
addLast() becomes O(1)
No need to traverse full list

‚ùó Interview-Ready Explanation
"I improved LinkedList insertion complexity from O(n) to O(1) by maintaining a tail pointer."

‚úÖ 7. Streams Question

You have:

class Book {
   String name;
   String author;
   LocalDate publishDate;
}

class Review {
   String name;
   int rating;
}

Requirement:

After 2021, find books whose rating > 4.

‚≠ê FIRST: NORMAL STREAM SOLUTION (Less optimal ‚Äì allowed in interviews)

This solution uses filtering + searching the review list for each book.

List<Book> result = books.stream()
        .filter(b -> b.getPublishDate().getYear() > 2021)
        .filter(b -> reviews.stream()
                .anyMatch(r -> r.getName().equals(b.getName()) && r.getRating() > 4))
        .collect(Collectors.toList());

‚ùå Complexity: O(n¬≤)
Because for each book you scan the reviews again.
Still acceptable for small lists but NOT optimal.

‚≠ê SECOND: OPTIMIZED STREAM SOLUTION (Best Answer for Interview)
Step 1 ‚Äî Convert review list into a Map for O(1) lookup
Map<String, Integer> ratingMap = reviews.stream()
        .collect(Collectors.toMap(Review::getName, Review::getRating));

Step 2 ‚Äî Filter books efficiently
List<Book> result = books.stream()
        .filter(b -> b.getPublishDate().getYear() > 2021)
        .filter(b -> ratingMap.getOrDefault(b.getName(), 0) > 4)
        .collect(Collectors.toList());

üëâ WHY THIS IS OPTIMAL
‚úî Only one pass for reviews ‚Üí O(n)
‚úî Only one pass for books ‚Üí O(n)
‚úî Map lookup per book ‚Üí O(1)
‚úî No nested loops
‚úî Avoids repeated scanning
Result: O(n) complexity (Best possible)
üü¢ FINAL CLARIFICATION


‚úÖ 8. Producer‚ÄìConsumer Problem Code ‚Äî Why While Loop Required?
‚úî Simplest Code Using wait/notify
class PC {
    Queue<Integer> queue = new LinkedList<>();
    int capacity = 5;

    public synchronized void produce() throws InterruptedException {
        while (queue.size() == capacity) {   // MUST BE WHILE
            wait();
        }
        queue.add(1);
        notifyAll();
    }

    public synchronized void consume() throws InterruptedException {
        while (queue.isEmpty()) {            // MUST BE WHILE
            wait();
        }
        queue.remove();
        notifyAll();
    }
}

| Reason                           | Explanation                              |
| -------------------------------- | ---------------------------------------- |
| **Spurious wakeup**              | Threads can wake without notify          |
| **Multiple producers/consumers** | After waking, condition may not be valid |
| **Data race avoidance**          | While rechecks condition                 |


IF checks once ‚Üí unsafe
WHILE checks condition repeatedly ‚Üí safe

‚úÖ 9. Critical or Complex Scenario From Your Experience

Use this answer in interviews:

‚≠ê Scenario: API slowness due to repeated DB calls

Problem:
API latency was 1.8 seconds
Due to N+1 queries + repeating DB calls

‚úî My multi-step solution:
Added Redis caching ‚Üí reduced repetitive queries
Fixed N+1 by using JOIN FETCH
Created indexes on frequently filtered columns
Used parallel streams for large dataset
Tuned HikariCP pool size

‚≠ê Result:
Reduced API latency from 1.8s ‚Üí 220ms
Reduced DB load by 70%

Interview Impact:
This proves performance optimization + real experience.

========================================================================================

06-12-2025	CCIL, dadar

1Ô∏è‚É£ Redis over relational databases
I don‚Äôt use Redis instead of RDBMS, I use it with RDBMS.

Why Redis?

In-memory ‚Üí microsecond‚Äìmillisecond latency.

Great for:
Caching frequently accessed data.
Storing sessions, tokens.
Counters, leaderboards, rate limiting.
Supports TTL ‚Üí automatic expiry.
Reduces load on relational DB ‚Üí improves overall throughput.

Line for interview:
‚ÄúWe kept relational DB as source of truth and used Redis as a caching + fast-access layer on top of it.‚Äù

2Ô∏è‚É£ Why Elasticsearch?

Built on Lucene ‚Üí optimized for full-text search.
Uses inverted index ‚Üí super-fast text queries on huge data.

Supports:
Full-text, fuzzy, relevance scoring.
Aggregations & analytics.
Horizontal scaling across nodes.
Great for logs, search boxes, analytics dashboards.

Line:
‚ÄúI use Elasticsearch where search & analytics on large text data are needed, not as a primary OLTP database.‚Äù

3Ô∏è‚É£ Microservices ‚Äì what & why?
Application split into small, independent services.

Each service:
Has its own codebase.
Can have its own DB.
Can be deployed, scaled independently.

Benefits: scalability, tech flexibility, fault isolation.

4Ô∏è‚É£ How do microservices communicate?

Two main ways:
Synchronous:
REST (HTTP/JSON)
gRPC (binary, faster)

Asynchronous:
Kafka / RabbitMQ / other message brokers.

Often: mixed ‚Äì REST for request/response, Kafka for events.

5Ô∏è‚É£ What if some microservices fail?

We use resilience patterns:
Timeouts ‚Üí don‚Äôt wait forever.
Retries with backoff.
Circuit breaker (e.g. Resilience4j).
Fallback (default or cached response).
Bulkhead (isolate resources per service).
Idempotency for safe retries.
For workflows: Saga pattern for distributed transactions.

6Ô∏è‚É£ Kafka ‚Äì where and why?

Distributed log-based message broker.
High throughput, partitioned, scalable.
Decouples producers & consumers.

Good for:
Event-driven architecture.
Streaming data.
Async communication between microservices.

Line:
‚ÄúI use Kafka to make services event-driven and to decouple communication instead of chaining synchronous REST calls.‚Äù

7Ô∏è‚É£ Get data from 3 microservices ‚Äì async but in sequence

Goal: call 3 services in parallel (for speed) but combine response in a specific order.

In Java (CompletableFuture):

CompletableFuture<Data1> f1 = supplyAsync(() -> callService1());
CompletableFuture<Data2> f2 = supplyAsync(() -> callService2());
CompletableFuture<Data3> f3 = supplyAsync(() -> callService3());

CompletableFuture.allOf(f1, f2, f3).join();

CombinedResponse resp = new CombinedResponse(
    f1.get(),  // first in sequence
    f2.get(),  // second
    f3.get()   // third
);


Calls run in parallel.
Final object respects desired sequence.

8Ô∏è‚É£ How do you find latency in code?

Add timing logs:

long start = System.currentTimeMillis();
// call
long end = System.currentTimeMillis();
log.info("Time taken: {} ms", (end - start));


Use APM tools: NewRelic, Datadog, Prometheus + Grafana.

Use Spring Boot Actuator metrics.

Check DB EXPLAIN plan for query latency.

Measure per-layer:
API layer
Service
Repository/DB

9Ô∏è‚É£ How to optimize an API?

Common points I‚Äôd say:

Add caching (Redis).
Use pagination, not full dumps.
Remove N+1 queries.
Add proper DB indexes.
Tune connection pool (HikariCP).
Avoid heavy object mapping / unnecessary transformations.
Compress response (gzip).

Use async/non-blocking where suitable.

üîü How to optimize SQL?

Create indexes on WHERE / JOIN columns.
Avoid SELECT * ‚Üí select only needed columns.
Avoid functions in WHERE on indexed columns (LOWER(col) breaks index).
Use EXPLAIN to see query plan.
Avoid unnecessary joins, subqueries.
Add limit/pagination where possible.

1Ô∏è‚É£1Ô∏è‚É£ What if I want 20k records from SQL ‚Äì how to optimize?

First: ask ‚Üí Do we really need all 20k at once?

If yes:

DB side:

Proper indexes.
Use server-side paging or streaming (cursor).
Use fetchSize hints (JDBC) for streaming results.

Example:

stmt.setFetchSize(1000);

1Ô∏è‚É£2Ô∏è‚É£ After optimizing SQL, how to optimize code for 20k records?

Avoid O(n¬≤) operations; use Map/Set for lookups.
Avoid creating unnecessary intermediate lists.
Use stream() or parallelStream() (carefully).
Avoid heavy operations inside loops (e.g. repeated DB calls or JSON parsing).

If sending to client:
Use pagination on API.
Or stream chunks (e.g. application/stream+json).

1Ô∏è‚É£3Ô∏è‚É£ Interface vs Abstract Class

Interface:
Only method signatures + default/static methods.
No state (except public static final constants).
A class can implement multiple interfaces.

Abstract class:
Can have:
Abstract + concrete methods.
Fields, constructors.
Single inheritance ‚Üí can extend only one abstract class.

Rule of thumb:
Use interface for contract; abstract class for shared partial implementation.

1Ô∏è‚É£4Ô∏è‚É£ What if I write body to an abstract method?

In Java:
An abstract method cannot have a body.
If you put a body, it is not abstract anymore.

You can have:

abstract class A {
    abstract void m1();      // no body
    void m2() { ... }        // normal concrete method
}


If you want default body in an interface ‚Üí use default method.

1Ô∏è‚É£5Ô∏è‚É£ Square / Circle extend Shape ‚Äì Find area without knowing shape

Polymorphism.

abstract class Shape {
    abstract double area();
}

class Circle extends Shape {
    double r;
    Circle(double r) { this.r = r; }
    double area() { return Math.PI * r * r; }
}

class Square extends Shape {
    double s;
    Square(double s) { this.s = s; }
    double area() { return s * s; }
}

// usage:
Shape s1 = new Circle(5);
Shape s2 = new Square(4);

double a1 = s1.area();   // calls Circle.area()
double a2 = s2.area();   // calls Square.area()


We don‚Äôt need to know whether it‚Äôs a circle or square.

1Ô∏è‚É£6Ô∏è‚É£ Batching

Batching = grouping multiple operations into one shot to reduce overhead.

Examples:

JDBC batch insert/update:

ps.addBatch();
ps.executeBatch();


Kafka batch sending.
Batch REST calls (where possible).

Benefits:
Fewer network calls.
Better throughput.

1Ô∏è‚É£7Ô∏è‚É£ Difference between @Component, @Service, @Repository

All are Spring beans but semantically different:
@Component
Generic bean.
Any component that doesn‚Äôt fit other stereotypes.

@Service
Service layer / business logic.
For readability + AOP (e.g. transactional, logging).

@Repository
DAO/persistence layer.
Spring translates DB exceptions into DataAccessException hierarchy.

1Ô∏è‚É£8Ô∏è‚É£ Throughput vs Latency
Latency = time taken to process one request
(e.g. 120 ms).

Throughput = number of requests processed per unit time
(e.g. 500 requests/second).

Analogy:
Latency: time to serve one customer.
Throughput: how many customers served per minute.

=====================================================================================